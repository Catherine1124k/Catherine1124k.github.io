---
layout: post
title: "Week 7"
date: 2021-03-01
---

Consider the following questions:

    Are the number of motorcycle deaths in a given year related to a state’s helmet laws?
    Does the number of employers conducting on-campus interviews during a year differ for public and private colleges?
    Does the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?
    Has the number of deformed fish in randomly selected Minnesota lakes been affected by changes in trace minerals in the water over the last decade?

Each example involves predicting a response using one or more explanatory variables, although these examples have response variables that are counts per some unit of time or space. A Poisson random variable is often used to model counts; see Chapter 3 for properties of the Poisson distribution. Since a Poisson random variable is a count, its minimum value is zero and, in theory, the maximum is unbounded. We’d like to model our main parameter λ, the average number of occurrences per unit of time or space, as a function of one or more covariates. For example, in the first question above, λi represents the average number of motorcycle deaths in a year for state i, and we hope to show that state-to-state variability in λi can be explained by state helmet laws.

For a linear least squares regression model, the parameter of interest is the average response, μi, for subject i, and μi is modeled as a line in the case of one explanatory variable. By analogy, it might seem reasonable to try to model the Poisson parameter λi as a linear function of an explanatory variable, but there are some problems with this approach. In fact, a model like λi=β0+β1xi doesn’t work well for Poisson data. A line is certain to yield negative values for certain xi, but λi can only take on values from 0 to ∞. In addition, the equal variance assumption in linear regression inference is violated because as the mean rate for a Poisson variable increases, the variance also increases (recall from Chapter 3 that if Y is the observed count, then E(Y)=Var(Y)=λ).

One way to avoid these problems is to model log(λi) instead of λi as a function of the covariates. The log(λi) takes on values from −∞ to ∞. We can also take into account the increase in the variance with an increasing mean using this approach. (Note that throughout Beyond Multiple Linear Regression we use log to represent the natural logarithm.) Thus, we will consider the Poisson regression model:

log(λi)=β0+β1xi where the observed values Yi∼ Poisson with λ=λi for a given xi. For example, each state i can potentially have a different λ depending on its value of xi, where xi could represent presence or absence of a particular helmet law. Note that the Poisson regression model contains no separate error term like the ϵ we see in linear regression, because λ determines both the mean and the variance of a Poisson random variable.

Thus far, we have expanded our repertoire of models from linear least squares regression to include Poisson regression. But in the early 1970s, Nelder and Wedderburn (1972) identified a broader class of models that generalizes the multiple linear regression we considered in the introductory chapter and are referred to as generalized linear models (GLMs). All GLMs have similar forms for their likelihoods, MLEs, and variances. This makes it easier to find model estimates and their corresponding uncertainty. To determine whether a model based on a single parameter θ

is a GLM, we consider the following properties. When a probability formula can be written in the form below

f(y;θ)=e[a(y)b(θ)+c(θ)+d(y)](5.1)
and if the support (the set of possible input values) does not depend upon θ, it is said to have a one-parameter exponential family form. We demonstrate that the Poisson distribution is a member of the one-parameter exponential family by writing its probability mass function (pmf) in the form of Equation (5.1) and assessing its support.

Logistic regression is characterized by research questions with binary (yes/no or success/failure) or binomial (number of yesses or successes in n

trials) responses:

    Are students with poor grades more likely to binge drink?
    Is exposure to a particular chemical associated with a cancer diagnosis?
    Are the number of votes for a congressional candidate associated with the amount of campaign contributions?

Binary Responses: Recall from Section 3.3.1 that binary responses take on only two values: success (Y=1) or failure (Y=0), Yes (Y=1) or No (Y=0), etc. Binary responses are ubiquitous; they are one of the most common types of data that statisticians encounter. We are often interested in modeling the probability of success p

based on a set of covariates, although sometimes we wish to use those covariates to classify a future observation as a success or a failure.

Examples (a) and (b) above would be considered to have binary responses (Does a student binge drink? Was a patient diagnosed with cancer?), assuming that we have a unique set of covariates for each individual student or patient.

Binomial Responses: Also recall from Section 3.3.2 that binomial responses are the number of successes in n
identical, independent trials with constant probability p of success. A sequence of independent trials like this with the same probability of success is called a Bernoulli process. As with binary responses, our objective in modeling binomial responses is to quantify how the probability of success, p

, is associated with relevant covariates.

Example (c) above would be considered to have a binomial response, assuming we have vote totals at the congressional district level rather than information on individual voters.
